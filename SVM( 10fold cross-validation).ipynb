{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed.\n",
      "0.7873931923238549\n",
      "0.7645975517278735\n",
      "0.7715418652871893\n",
      "0.7888888888888889\n",
      "Fold completed.\n",
      "0.8099448414684203\n",
      "0.7825364933573888\n",
      "0.7902659427845492\n",
      "0.8055555555555556\n",
      "Fold completed.\n",
      "0.7714591356439879\n",
      "0.7438699360341151\n",
      "0.7506020757725245\n",
      "0.77\n",
      "Fold completed.\n",
      "0.7804643917988843\n",
      "0.740108541155188\n",
      "0.7489111926237337\n",
      "0.7744444444444445\n",
      "Fold completed.\n",
      "0.8063153388608508\n",
      "0.780267579212105\n",
      "0.7880936454849499\n",
      "0.8044444444444444\n",
      "Fold completed.\n",
      "0.5035222767675448\n",
      "0.536291157589563\n",
      "0.3281777991478677\n",
      "0.4411111111111111\n",
      "Fold completed.\n",
      "0.5218181818181818\n",
      "0.6165501165501166\n",
      "0.34306201897261496\n",
      "0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed.\n",
      "0.5\n",
      "0.3566666666666667\n",
      "0.4163424124513619\n",
      "0.7133333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed.\n",
      "0.5\n",
      "0.3861111111111111\n",
      "0.4357366771159875\n",
      "0.7722222222222223\n",
      "Fold completed.\n",
      "0.5640840508182048\n",
      "0.5799418873651287\n",
      "0.5361685460430023\n",
      "0.5555555555555556\n",
      "\n",
      "Precision Accuracy: 0.655\n",
      "\n",
      "Recall Accuracy: 0.629\n",
      "\n",
      "f1 Accuracy: 0.591\n",
      "\n",
      "Average Accuracy: 0.685\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import operator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "nltk.download('stopwords') # If needed\n",
    "nltk.download('punkt') # If needed\n",
    "nltk.download('wordnet') # If needed\n",
    "dataset_full=pd.read_csv(\"hateval.tsv\",sep='\\t')\n",
    "dataset_text=dataset_full['text']\n",
    "dataset_label=dataset_full['label']\n",
    "dataset_list=[]\n",
    "for i in range(len(dataset_text)):\n",
    "    for j in range(len(dataset_label)):\n",
    "        if i==j:\n",
    "            dataset_list.append((dataset_text[i],dataset_label[j]))\n",
    "dataset_fixed=[]\n",
    "link = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]{2}))+')\n",
    "#label = re.compile(r'[@][0-9a-zA-Z\\_]*')\n",
    "for speech in range(len(dataset_text)):\n",
    "    url_1 = re.findall(link, dataset_text[speech])\n",
    "    #url_2 = re.findall(label, dataset_text[speech])\n",
    "    dataset_fixed.append(dataset_text[speech].strip(str(url_1)))\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(dataset_full)\n",
    "accuracy_total=0.0\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def get_list_tokens(string): # Function to retrieve the list of tokens from a string\n",
    "    sentence_split=nltk.tokenize.sent_tokenize(string)\n",
    "    list_tokens=[]\n",
    "    for sentence in sentence_split:\n",
    "        list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "        for token in list_tokens_sentence:\n",
    "            list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    return list_tokens\n",
    "\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"--\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"#\")\n",
    "stopwords.add(\"@\")\n",
    "stopwords.add(\"'\")\n",
    "\n",
    "def get_vector_text(list_vocab,string):\n",
    "    vector_text=np.zeros(len(list_vocab))\n",
    "    list_tokens_string=get_list_tokens(string)\n",
    "    for i, word in enumerate(list_vocab):\n",
    "        if word in list_tokens_string:\n",
    "            vector_text[i]=list_tokens_string.count(word)  \n",
    "    return vector_text\n",
    "\n",
    "def get_vocabulary(training_set, num_features): # Function to retrieve vocabulary\n",
    "    dict_word_frequency={}\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            if word not in dict_word_frequency: \n",
    "                dict_word_frequency[word]=1\n",
    "            else: \n",
    "                dict_word_frequency[word]+=1\n",
    "    sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "        vocabulary.append(word)\n",
    "    return vocabulary\n",
    "\n",
    "def train_svm_classifier(training_set, vocabulary): # Function for training our svm classifier\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    for instance in training_set:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_train.append(vector_instance)\n",
    "        Y_train.append(instance[1])\n",
    "        # Finally, we train the SVM classifier \n",
    "    #print(X_train)\n",
    "    svm_clf=SVC(kernel=\"linear\",gamma='auto')\n",
    "    svm_clf.fit(X_train,Y_train)\n",
    "    return svm_clf\n",
    "\n",
    "precision_total=0\n",
    "recall_total=0\n",
    "f1_total=0\n",
    "for train_index, test_index in kf.split(dataset_list):\n",
    "    train_set_fold=[]\n",
    "    test_set_fold=[]\n",
    "    for i,instance in enumerate(dataset_list):\n",
    "        if i in train_index:\n",
    "            train_set_fold.append(instance)\n",
    "        else:\n",
    "            test_set_fold.append(instance)\n",
    "    #print(train_set_fold)\n",
    "    vocabulary_fold=get_vocabulary(train_set_fold, 500)\n",
    "    svm_clf_fold=train_svm_classifier(train_set_fold, vocabulary_fold)\n",
    "    X_test_fold=[]\n",
    "    Y_test_fold=[]\n",
    "    for instance in test_set_fold:\n",
    "        vector_instance=get_vector_text(vocabulary_fold,instance[0])\n",
    "        X_test_fold.append(vector_instance)\n",
    "        Y_test_fold.append(instance[1])\n",
    "    Y_test_fold_gold=np.asarray(Y_test_fold)\n",
    "    X_test_fold=np.asarray(X_test_fold)\n",
    "    Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n",
    "    precision_fold=precision_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "    recall_fold=recall_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "    f1_fold=f1_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "    accuracy_fold=accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)\n",
    "    precision_total+=precision_fold\n",
    "    recall_total+=recall_fold\n",
    "    f1_total+=f1_fold\n",
    "    accuracy_total+=accuracy_fold\n",
    "    print (\"Fold completed.\")\n",
    "    print(precision_fold)\n",
    "    print(recall_fold)\n",
    "    print(f1_fold)\n",
    "    print(accuracy_fold)\n",
    "precision_accuracy=precision_total/10\n",
    "recall_accuracy=recall_total/10\n",
    "f1_accuracy=f1_total/10\n",
    "average_accuracy=accuracy_total/10\n",
    "print (\"\\nPrecision Accuracy: \"+str(round(precision_accuracy,3)))\n",
    "print (\"\\nRecall Accuracy: \"+str(round(recall_accuracy,3)))\n",
    "print (\"\\nf1 Accuracy: \"+str(round(f1_accuracy,3)))\n",
    "print (\"\\nAverage Accuracy: \"+str(round(average_accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
